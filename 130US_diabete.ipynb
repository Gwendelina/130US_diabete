{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f05b9362",
   "metadata": {},
   "source": [
    "# Bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da71903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 51)\n",
    "import numpy as np\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn : apprentissage automatique\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn import set_config # Pour afficher les pipelines\n",
    "set_config(display='diagram')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c3d568",
   "metadata": {},
   "source": [
    "# Import du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17abc6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('diabetic_data_130US_hospital.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d53248a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>payer_code</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>diag_1</th>\n",
       "      <th>diag_2</th>\n",
       "      <th>diag_3</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>max_glu_serum</th>\n",
       "      <th>A1Cresult</th>\n",
       "      <th>metformin</th>\n",
       "      <th>repaglinide</th>\n",
       "      <th>nateglinide</th>\n",
       "      <th>chlorpropamide</th>\n",
       "      <th>glimepiride</th>\n",
       "      <th>acetohexamide</th>\n",
       "      <th>glipizide</th>\n",
       "      <th>glyburide</th>\n",
       "      <th>tolbutamide</th>\n",
       "      <th>pioglitazone</th>\n",
       "      <th>rosiglitazone</th>\n",
       "      <th>acarbose</th>\n",
       "      <th>miglitol</th>\n",
       "      <th>troglitazone</th>\n",
       "      <th>tolazamide</th>\n",
       "      <th>examide</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>Pediatrics-Endocrinology</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.83</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>250.01</td>\n",
       "      <td>255</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>648</td>\n",
       "      <td>250</td>\n",
       "      <td>V27</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>250.43</td>\n",
       "      <td>403</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>157</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
       "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
       "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
       "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
       "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
       "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
       "\n",
       "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                  6                        25                    1   \n",
       "1                  1                         1                    7   \n",
       "2                  1                         1                    7   \n",
       "3                  1                         1                    7   \n",
       "4                  1                         1                    7   \n",
       "\n",
       "   time_in_hospital payer_code         medical_specialty  num_lab_procedures  \\\n",
       "0                 1          ?  Pediatrics-Endocrinology                  41   \n",
       "1                 3          ?                         ?                  59   \n",
       "2                 2          ?                         ?                  11   \n",
       "3                 2          ?                         ?                  44   \n",
       "4                 1          ?                         ?                  51   \n",
       "\n",
       "   num_procedures  num_medications  number_outpatient  number_emergency  \\\n",
       "0               0                1                  0                 0   \n",
       "1               0               18                  0                 0   \n",
       "2               5               13                  2                 0   \n",
       "3               1               16                  0                 0   \n",
       "4               0                8                  0                 0   \n",
       "\n",
       "   number_inpatient  diag_1  diag_2 diag_3  number_diagnoses max_glu_serum  \\\n",
       "0                 0  250.83       ?      ?                 1          None   \n",
       "1                 0     276  250.01    255                 9          None   \n",
       "2                 1     648     250    V27                 6          None   \n",
       "3                 0       8  250.43    403                 7          None   \n",
       "4                 0     197     157    250                 5          None   \n",
       "\n",
       "  A1Cresult metformin repaglinide nateglinide chlorpropamide glimepiride  \\\n",
       "0      None        No          No          No             No          No   \n",
       "1      None        No          No          No             No          No   \n",
       "2      None        No          No          No             No          No   \n",
       "3      None        No          No          No             No          No   \n",
       "4      None        No          No          No             No          No   \n",
       "\n",
       "  acetohexamide glipizide glyburide tolbutamide pioglitazone rosiglitazone  \\\n",
       "0            No        No        No          No           No            No   \n",
       "1            No        No        No          No           No            No   \n",
       "2            No    Steady        No          No           No            No   \n",
       "3            No        No        No          No           No            No   \n",
       "4            No    Steady        No          No           No            No   \n",
       "\n",
       "  acarbose miglitol troglitazone tolazamide examide citoglipton insulin  \\\n",
       "0       No       No           No         No      No          No      No   \n",
       "1       No       No           No         No      No          No      Up   \n",
       "2       No       No           No         No      No          No      No   \n",
       "3       No       No           No         No      No          No      Up   \n",
       "4       No       No           No         No      No          No  Steady   \n",
       "\n",
       "  glyburide-metformin glipizide-metformin glimepiride-pioglitazone  \\\n",
       "0                  No                  No                       No   \n",
       "1                  No                  No                       No   \n",
       "2                  No                  No                       No   \n",
       "3                  No                  No                       No   \n",
       "4                  No                  No                       No   \n",
       "\n",
       "  metformin-rosiglitazone metformin-pioglitazone change diabetesMed readmitted  \n",
       "0                      No                     No     No          No         NO  \n",
       "1                      No                     No     Ch         Yes        >30  \n",
       "2                      No                     No     No         Yes         NO  \n",
       "3                      No                     No     Ch         Yes         NO  \n",
       "4                      No                     No     Ch         Yes         NO  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f21601",
   "metadata": {},
   "source": [
    "# Principales informations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22851a1b",
   "metadata": {},
   "source": [
    "## Source et vue d'ensemble du dataset  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994632c0",
   "metadata": {},
   "source": [
    "Ce dataset est hébergé sur le site opensource du \"Center for Machine Learning and Intelligent Systems\" de l'Université de Californie, qui regroupe des données permettant de faire du machine learning. \n",
    "\n",
    "Notre dataset traite du diabète et représente les données sur 10 ans (1999-2008), de 130 hôpitaux américains, des patients ayant été admis (patients hospitalisés) pour ce type de problème : https://archive.ics.uci.edu/ml/datasets/diabetes+130-us+hospitals+for+years+1999-2008\n",
    "\n",
    "Le dataset compte 101766 exemples et 50 features. Chaque ligne correspond à l'admission unique d'un patient. A noter qu'un patient peut être admis plusieurs fois. Le nombre de patients total ayant été admis sur la période est de 71518. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9edc07ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101766, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cc76769",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101766, 71518)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['encounter_id'].nunique(), data['patient_nbr'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5359ac89",
   "metadata": {},
   "source": [
    "## Quelles sont mes variables ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccfc9df",
   "metadata": {},
   "source": [
    "Le dataset présente des variables relatives aux caractéristiques physiques du patient, à la nature de sa prise en charge médicale (spécialité du médecin, temps d'hospitalisation...), à ses traitements médicaux et à ses résultats de tests de sanguins. \n",
    "\n",
    "Voici le détail : \n",
    "\n",
    "**encounter_id** : identifiant unique de l'admission \n",
    "\n",
    "**patient_nbr** : identifiant unique du patient  \n",
    "\n",
    "**race** : 'Caucasian', 'AfricanAmerican', 'Other', 'Asian', 'Hispanic'\n",
    "\n",
    "**gender** : homme ou femme  \n",
    "\n",
    "**age** : groupé par des intervalles de 10 années  \n",
    "\n",
    "**weight** : poids du patient en livre (A TRADUIRE EN KG)  \n",
    "\n",
    "**admission_type_id** : id correspondant à 8 modalités (Emergency, Urgent, Elective, Newborn, Not Available, NULL, Trauma Center, Not Mapped  (voir dans le détail à quoi cela correspond))  \n",
    "\n",
    "**discharge_disposition_id** : lieu de transfert après guérison - 26 modalités (voir fichier excel) - A la maison, dans un autre service, etc.    \n",
    "\n",
    "**admission_source_id** : raison de l'admission (recommandation médicale/urgence/enfant malade..) - 17 modalités.   \n",
    "\n",
    "**time_in_hospital** : nombre de jours entre l'admission et la sortie (va de 1 à 14 jours) \n",
    "\n",
    "**payer_code** : unique ID assigné à chaque compagnie (RETROUVER NOM ENTIER DE CHAQUE MODALITE)   \n",
    "\n",
    "**medical_specialty** : correspond à la spécialité du médecin qui a pris en charge le patient à son arrivée - 73 modalités \n",
    "\n",
    "**num_lab_procedures** : nombre de tests labo faits pendant l'hospitalisation  \n",
    "\n",
    "**num_procedures** : nombre de procédures (interventions) autre que les tests en labo  \n",
    "\n",
    "**num_medications** : nombre de médicaments administrés lors de l'encounter (ou Number of distinct generic names administered during the encounter) - A VERIFIER   \n",
    "\n",
    "**number_outpatient** : Nombre de visites ambulatoires du patient dans l'année précédant la consultation (consultation externe)   \n",
    "\n",
    "**number_emergency** : Nombre de visites aux urgences du patient dans l'année précédant la consultation  \n",
    "\n",
    "**number_inpatient** : Nombre de visites hospitalières du patient dans l'année précédant la consultation  \n",
    "\n",
    "**diag_1/2/3** : Premier, second et diagnostique additionnel. Correspond au code ICD9 (documentation pour la classification : https://www2.gov.bc.ca/gov/content/health/practitioner-professional-resources/msp/physicians/diagnostic-code-descriptions-icd-9)  \n",
    "\n",
    "**number_diagnoses** : nombre de diagnostics déclarés dans le système  \n",
    "\n",
    "**max_glu_serum** : 4 modalités - Glycémie à jeun (A VERIFIER)  \n",
    "\n",
    "**A1Cresult** : HbA1c = hémoglobine glyquée  \n",
    "\n",
    "**Medications : metformin -> metformin-pioglitazone** : types de médicaments pris avec 4 modalités (régulier, pas pris, augmenté, diminué)   \n",
    "\n",
    "**change** : indique s'il y a eu un changement dans la traitement pour le diabète, soit dans la posologie, soit dans le nom du médicament  \n",
    "\n",
    "**diabetesMed** : prescription de médicaments pour le diabète ou pas  \n",
    "\n",
    "**readmitted** :  le patient a-t-il été réadmis au bout de 30 jours max, à plus de 30 jours ou pas réadmis ?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a687ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['encounter_id', 'patient_nbr', 'race', 'gender', 'age', 'weight',\n",
       "       'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
       "       'time_in_hospital', 'payer_code', 'medical_specialty',\n",
       "       'num_lab_procedures', 'num_procedures', 'num_medications',\n",
       "       'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_1',\n",
       "       'diag_2', 'diag_3', 'number_diagnoses', 'max_glu_serum', 'A1Cresult',\n",
       "       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
       "       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
       "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
       "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
       "       'glyburide-metformin', 'glipizide-metformin',\n",
       "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
       "       'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############\n",
    "# A faire ? Requalifier les colonnes pour une meilleure compréhension ?\n",
    "#############\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "badd8f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encounter_id: [  2278392    149190     64410 ... 443854148 443857166 443867222]\n",
      "Nb de modalités : 101766\n",
      "\n",
      "patient_nbr: [  8222157  55629189  86047875 ... 140199494 120975314 175429310]\n",
      "Nb de modalités : 71518\n",
      "\n",
      "race: ['Caucasian' 'AfricanAmerican' '?' 'Other' 'Asian' 'Hispanic']\n",
      "Nb de modalités : 6\n",
      "\n",
      "gender: ['Female' 'Male' 'Unknown/Invalid']\n",
      "Nb de modalités : 3\n",
      "\n",
      "age: ['[0-10)' '[10-20)' '[20-30)' '[30-40)' '[40-50)' '[50-60)' '[60-70)'\n",
      " '[70-80)' '[80-90)' '[90-100)']\n",
      "Nb de modalités : 10\n",
      "\n",
      "weight: ['?' '[75-100)' '[50-75)' '[0-25)' '[100-125)' '[25-50)' '[125-150)'\n",
      " '[175-200)' '[150-175)' '>200']\n",
      "Nb de modalités : 10\n",
      "\n",
      "admission_type_id: [6 1 2 3 4 5 8 7]\n",
      "Nb de modalités : 8\n",
      "\n",
      "discharge_disposition_id: [25  1  3  6  2  5 11  7 10  4 14 18  8 13 12 16 17 22 23  9 20 15 24 28\n",
      " 19 27]\n",
      "Nb de modalités : 26\n",
      "\n",
      "admission_source_id: [ 1  7  2  4  5  6 20  3 17  8  9 14 10 22 11 25 13]\n",
      "Nb de modalités : 17\n",
      "\n",
      "time_in_hospital: [ 1  3  2  4  5 13 12  9  7 10  6 11  8 14]\n",
      "Nb de modalités : 14\n",
      "\n",
      "payer_code: ['?' 'MC' 'MD' 'HM' 'UN' 'BC' 'SP' 'CP' 'SI' 'DM' 'CM' 'CH' 'PO' 'WC' 'OT'\n",
      " 'OG' 'MP' 'FR']\n",
      "Nb de modalités : 18\n",
      "\n",
      "medical_specialty: ['Pediatrics-Endocrinology' '?' 'InternalMedicine'\n",
      " 'Family/GeneralPractice' 'Cardiology' 'Surgery-General' 'Orthopedics'\n",
      " 'Gastroenterology' 'Surgery-Cardiovascular/Thoracic' 'Nephrology'\n",
      " 'Orthopedics-Reconstructive' 'Psychiatry' 'Emergency/Trauma'\n",
      " 'Pulmonology' 'Surgery-Neuro' 'Obsterics&Gynecology-GynecologicOnco'\n",
      " 'ObstetricsandGynecology' 'Pediatrics' 'Hematology/Oncology'\n",
      " 'Otolaryngology' 'Surgery-Colon&Rectal' 'Pediatrics-CriticalCare'\n",
      " 'Endocrinology' 'Urology' 'Psychiatry-Child/Adolescent'\n",
      " 'Pediatrics-Pulmonology' 'Neurology' 'Anesthesiology-Pediatric'\n",
      " 'Radiology' 'Pediatrics-Hematology-Oncology' 'Psychology' 'Podiatry'\n",
      " 'Gynecology' 'Oncology' 'Pediatrics-Neurology' 'Surgery-Plastic'\n",
      " 'Surgery-Thoracic' 'Surgery-PlasticwithinHeadandNeck' 'Ophthalmology'\n",
      " 'Surgery-Pediatric' 'Pediatrics-EmergencyMedicine'\n",
      " 'PhysicalMedicineandRehabilitation' 'InfectiousDiseases' 'Anesthesiology'\n",
      " 'Rheumatology' 'AllergyandImmunology' 'Surgery-Maxillofacial'\n",
      " 'Pediatrics-InfectiousDiseases' 'Pediatrics-AllergyandImmunology'\n",
      " 'Dentistry' 'Surgeon' 'Surgery-Vascular' 'Osteopath'\n",
      " 'Psychiatry-Addictive' 'Surgery-Cardiovascular' 'PhysicianNotFound'\n",
      " 'Hematology' 'Proctology' 'Obstetrics' 'SurgicalSpecialty' 'Radiologist'\n",
      " 'Pathology' 'Dermatology' 'SportsMedicine' 'Speech' 'Hospitalist'\n",
      " 'OutreachServices' 'Cardiology-Pediatric' 'Perinatology'\n",
      " 'Neurophysiology' 'Endocrinology-Metabolism' 'DCPTEAM' 'Resident']\n",
      "Nb de modalités : 73\n",
      "\n",
      "num_lab_procedures: [ 41  59  11  44  51  31  70  73  68  33  47  62  60  55  49  75  45  29\n",
      "  35  42  66  36  19  64  25  53  52  87  27  37  46  28  48  72  10   2\n",
      "  65  67  40  54  58  57  43  32  83  34  39  69  38  56  22  96  78  61\n",
      "  88  50   1  18  82   9  63  24  71  77  81  76  90  93   3 103  13  80\n",
      "  85  16  15  12  30  23  17  21  79  26   5  95  97  84  14  74 105  86\n",
      "  98  20   6  94   8 102 100   7  89  91  92   4 101  99 114 113 111 129\n",
      " 107 108 106 104 109 120 132 121 126 118]\n",
      "Nb de modalités : 118\n",
      "\n",
      "num_procedures: [0 5 1 6 2 3 4]\n",
      "Nb de modalités : 7\n",
      "\n",
      "num_medications: [ 1 18 13 16  8 21 12 28 17 11 15 31  2 23 19  7 20 14 10 22  9 27 25  4\n",
      " 32  6 30 26 24 33  5 39  3 29 61 40 46 41 36 34 35 50 43 42 37 51 38 45\n",
      " 54 52 49 62 55 47 44 53 48 57 59 56 60 63 58 70 67 64 69 65 68 66 81 79\n",
      " 75 72 74]\n",
      "Nb de modalités : 75\n",
      "\n",
      "number_outpatient: [ 0  2  1  5  7  9  3  8  4 12 11  6 20 15 10 13 14 16 21 35 17 29 36 18\n",
      " 19 27 22 24 42 39 34 26 33 25 23 28 37 38 40]\n",
      "Nb de modalités : 39\n",
      "\n",
      "number_emergency: [ 0  1  2  4  3  9  5  7  6  8 22 25 10 13 42 16 11 28 15 14 18 12 21 20\n",
      " 19 46 76 37 64 63 54 24 29]\n",
      "Nb de modalités : 33\n",
      "\n",
      "number_inpatient: [ 0  1  2  3  6  5  4  7  8  9 15 10 11 14 12 13 17 16 21 18 19]\n",
      "Nb de modalités : 21\n",
      "\n",
      "diag_1: ['250.83' '276' '648' '8' '197' '414' '428' '398' '434' '250.7' '157'\n",
      " '518' '999' '410' '682' '402' '737' '572' 'V57' '189' '786' '427' '996'\n",
      " '277' '584' '462' '473' '411' '174' '486' '998' '511' '432' '626' '295'\n",
      " '196' '250.6' '618' '182' '845' '423' '808' '250.4' '722' '403' '250.11'\n",
      " '784' '707' '440' '151' '715' '997' '198' '564' '812' '38' '590' '556'\n",
      " '578' '250.32' '433' 'V58' '569' '185' '536' '255' '250.13' '599' '558'\n",
      " '574' '491' '560' '244' '250.03' '577' '730' '188' '824' '250.8' '332'\n",
      " '562' '291' '296' '510' '401' '263' '438' '70' '250.02' '493' '642' '625'\n",
      " '571' '738' '593' '250.42' '807' '456' '446' '575' '250.41' '820' '515'\n",
      " '780' '250.22' '995' '235' '250.82' '721' '787' '162' '724' '282' '514'\n",
      " 'V55' '281' '250.33' '530' '466' '435' '250.12' 'V53' '789' '566' '822'\n",
      " '191' '557' '733' '455' '711' '482' '202' '280' '553' '225' '154' '441'\n",
      " '250.81' '349' '?' '962' '592' '507' '386' '156' '200' '728' '348' '459'\n",
      " '426' '388' '607' '337' '82' '531' '596' '288' '656' '573' '492' '220'\n",
      " '516' '210' '922' '286' '885' '958' '661' '969' '250.93' '227' '112'\n",
      " '404' '823' '532' '416' '346' '535' '453' '250' '595' '211' '303'\n",
      " '250.01' '852' '218' '782' '540' '457' '285' '431' '340' '550' '54' '351'\n",
      " '601' '723' '555' '153' '443' '380' '204' '424' '241' '358' '694' '331'\n",
      " '345' '681' '447' '290' '158' '579' '436' '335' '309' '654' '805' '799'\n",
      " '292' '183' '78' '851' '458' '586' '311' '892' '305' '293' '415' '591'\n",
      " '794' '803' '79' '655' '429' '278' '658' '598' '729' '585' '444' '604'\n",
      " '727' '214' '552' '284' '680' '708' '41' '644' '481' '821' '413' '437'\n",
      " '968' '756' '632' '359' '275' '512' '781' '420' '368' '522' '294' '825'\n",
      " '135' '304' '320' '250.31' '669' '868' '496' '250.43' '826' '567' '3'\n",
      " '203' '53' '251' '565' '161' '495' '49' '250.1' '297' '663' '576' '355'\n",
      " '850' '287' '250.2' '611' '840' '350' '726' '537' '620' '180' '366' '783'\n",
      " '11' '751' '716' '250.3' '199' '464' '580' '836' '664' '283' '813' '966'\n",
      " '289' '965' '184' '480' '608' '333' '972' '212' '117' '788' '924' '959'\n",
      " '621' '238' '785' '714' '942' '250.23' '710' '47' '933' '508' '478' '844'\n",
      " '7' '736' '233' '42' '250.5' '397' '395' '201' '421' '253' '250.92' '600'\n",
      " '494' '977' '39' '659' '312' '614' '647' '652' '646' '274' '861' '425'\n",
      " '527' '451' '485' '217' '250.53' '442' '970' '193' '160' '322' '581'\n",
      " '475' '623' '374' '582' '568' '465' '801' '237' '376' '150' '461' '913'\n",
      " '226' '617' '987' '641' '298' '790' '336' '362' '228' '513' '383' '746'\n",
      " '353' '911' '506' '873' '155' '860' '534' '802' '141' 'V45' '396' '310'\n",
      " '341' '242' '719' '239' '533' '616' '519' '301' 'V66' '5' '989' '230'\n",
      " '385' '300' '853' '871' '570' '848' '463' '9' '934' '250.21' '236' '361'\n",
      " '594' '501' '810' '643' '430' '528' '205' '791' '983' '992' '490' '172'\n",
      " '171' '622' '306' '863' '864' '474' '660' '759' '356' '634' '967' '551'\n",
      " '695' '187' '732' '747' '323' '308' '370' '252' '152' '846' '164' '365'\n",
      " '718' '48' '266' '720' '94' '344' '797' '170' '878' '904' 'V56' '882'\n",
      " '843' '709' '973' '454' '686' '939' '487' '229' '991' '483' '357' '692'\n",
      " '796' '693' '935' '936' '800' '920' 'V26' '261' '307' '262' '250.9' '831'\n",
      " '145' '223' 'V71' '839' '685' 'V54' '35' '34' '179' '964' '136' '324'\n",
      " '389' '815' '334' '143' '526' '588' '192' 'V67' '394' '917' '88' '219'\n",
      " '325' '792' '717' '994' '990' '793' '207' '637' '195' '373' '847' '827'\n",
      " '31' '891' '814' 'V60' '703' '865' '352' '627' '378' '342' '886' '369'\n",
      " '745' '705' '816' '541' '986' '610' '633' '640' '753' '173' '835' '379'\n",
      " '445' '272' '382' '945' '619' '881' '250.52' '866' '405' '916' '215'\n",
      " '893' '75' '671' '928' '906' '897' '725' '867' '115' '890' '734' '521'\n",
      " '674' '470' '834' '146' '696' '524' '980' '691' '384' '142' '879'\n",
      " '250.51' '246' '208' '448' '955' '653' '149' '245' '735' '883' '854'\n",
      " '952' '838' '194' 'V43' '163' '216' '147' '354' '27' '477' '318' '880'\n",
      " '921' '377' '471' '683' '175' '602' '250.91' '982' '706' '375' '417'\n",
      " '131' '347' '870' '148' '862' '61' '817' '914' '360' '684' '314' 'V63'\n",
      " '36' '57' '240' '915' '971' '795' '988' '452' '963' '327' '731' '842'\n",
      " 'V25' '645' '665' '110' '944' '603' '923' '412' '363' '957' '976' '698'\n",
      " '299' '700' '273' '974' '97' '529' '66' '98' '605' '941' '52' '806' '84'\n",
      " '271' '837' '657' '895' '338' '523' '542' '114' '543' '372' 'V70' 'E909'\n",
      " '583' 'V07' '422' '615' '279' '500' '903' '919' '875' '381' '804' '704'\n",
      " '23' '58' '649' '832' '133' '975' '833' '391' '690' '10' 'V51']\n",
      "Nb de modalités : 717\n",
      "\n",
      "diag_2: ['?' '250.01' '250' '250.43' '157' '411' '492' '427' '198' '403' '288'\n",
      " '998' '507' '174' '425' '456' '401' '715' '496' '428' '585' '250.02'\n",
      " '410' '999' '996' '135' '244' '41' '571' '276' '997' '599' '424' '491'\n",
      " '553' '707' '286' '440' '493' '242' '70' 'V45' '250.03' '357' '511' '196'\n",
      " '396' '197' '414' '250.52' '577' '535' '413' '285' '53' '780' '518' '150'\n",
      " '566' '250.6' '867' '486' 'V15' '8' '788' '340' '574' '581' '228' '530'\n",
      " '250.82' '786' '294' '567' '785' '512' '305' '729' '250.51' '280' '648'\n",
      " '560' '618' '444' '38' 'V10' '578' '277' '781' '250.42' '278' '426' '584'\n",
      " '462' '402' '153' '272' '733' '34' '881' '203' '250.41' '250.13' '293'\n",
      " '245' '250.12' '558' '787' '342' '573' '626' '303' '250.53' '458' '710'\n",
      " '415' 'V42' '284' '569' '759' '682' '112' '292' '435' '290' '250.93'\n",
      " '642' '536' '398' '319' '711' 'E878' '446' '255' 'V44' '250.7' '784'\n",
      " '300' '562' '162' '287' '447' '789' '790' '591' '200' '154' '304' '117'\n",
      " '847' '852' '250.83' '250.11' '816' '575' '416' '412' '441' '515' '372'\n",
      " '482' '382' 'V65' '572' '283' '78' '250.81' '576' '432' '595' '295' 'V12'\n",
      " '204' '466' '721' '434' '590' '271' '813' '368' '227' '783' '250.5' '258'\n",
      " '253' '309' '250.91' '519' '333' '459' '250.92' '250.4' '179' '420' '345'\n",
      " '433' '661' '537' '205' '722' '405' '437' '714' '211' 'E812' '263' '202'\n",
      " '397' '250.23' 'E932' '201' '301' '723' '614' '568' '861' 'V57' '724'\n",
      " '189' '297' '453' 'E888' '730' '354' '451' '738' 'E939' '805' 'V43' '155'\n",
      " '910' '218' '358' '220' 'E937' '583' '958' '794' '564' '436' '250.22'\n",
      " '620' '621' '331' '617' '596' '314' '378' '250.8' '625' '478' '731' '172'\n",
      " '404' '681' '470' '279' '281' '531' '443' '799' '337' '311' '719' 'E944'\n",
      " '423' 'E870' '465' 'E849' '782' '481' '480' 'V23' '199' '79' '438' '348'\n",
      " '42' 'E950' '473' '627' '726' '54' '490' '317' '332' '508' '369' '600'\n",
      " '349' '485' '208' '922' '431' '296' 'E934' '753' 'E935' '386' '728' '607'\n",
      " 'E915' '344' '716' '289' '191' '873' '850' '611' '377' '352' '616' 'V17'\n",
      " '136' '455' '933' 'E885' '860' '513' '603' '484' '223' 'V72' '291' '151'\n",
      " 'V58' '550' '510' '891' '185' '592' '791' '138' '598' '336' '362' '217'\n",
      " '825' '298' '821' 'E880' '343' '429' 'E879' '579' '225' '250.9' 'V49'\n",
      " '696' '233' '658' '969' '275' '250.1' '601' '704' '808' 'E890' 'V18'\n",
      " '920' '380' '570' 'E817' '359' '812' '274' 'V14' '324' '758' 'V66' '911'\n",
      " 'E931' 'E924' '593' '792' '727' 'V46' '394' '532' 'V64' '557' '864' '718'\n",
      " 'E942' '807' '604' '924' '820' '580' '273' '241' '282' '824' 'V61' '646'\n",
      " '701' '736' '565' '383' '250.2' 'E947' '452' '872' '905' 'E930' '921'\n",
      " '131' '448' '389' '421' '214' '705' '494' '752' '623' '9' '299' '959'\n",
      " '365' '967' 'E858' '40' '691' '909' '5' '814' '746' '250.31' '556' '680'\n",
      " '745' '351' '306' '110' '695' '552' '346' '918' '882' '947' '520' '188'\n",
      " '31' '356' '737' 'V08' '322' '182' '517' '974' 'E929' 'V53' '912' '252'\n",
      " '608' '516' 'E933' '94' '702' '923' '594' '647' '111' '934' '430' '487'\n",
      " '709' '796' '156' '977' '915' '756' '840' '341' '259' '693' '725' 'V62'\n",
      " '528' '683' '953' '457' '501' 'E900' 'V09' '522' '919' '461' '506' '193'\n",
      " '483' 'E936' '717' '802' '335' 'V54' '320' '945' '906' '239' '454' '826'\n",
      " '823' 'E941' '226' '795' '684' '844' '250.33' '308' '615' '588' '712'\n",
      " '663' '706' '833' '741' '713' '533' 'E884' '586' '555' '755' 'E928' '742'\n",
      " '869' '962' 'V11' '543' '373' '870' '913' '152' '810' '965' '907' '908'\n",
      " '995' '845' '474' '442' '751' '323' '472' '464' '686' '250.32' '540'\n",
      " '251' '811' '652' '659' '851' '422' '815' '307' '325' '463' '992' '692'\n",
      " '521' '917' 'E965' '524' '916' 'E813' '173' '238' '137' '514' '312' '837'\n",
      " '355' '980' '622' '475' '500' '754' '261' '801' '868' '968' '381' '11'\n",
      " '250.21' '694' '610' '734' 'E814' '310' '130' '246' '892' '846' '634'\n",
      " '75' 'E927' 'E905' '183' '379' 'E917' '163' 'E868' '495' '747' '989'\n",
      " 'E854' '240' '832' '605' '602' '644' 'V16' '35' 'V70' '376' '266' 'E918'\n",
      " '619' '477' '656' '46' '883' '171' 'V13' '698' '842' 'E850' '800' '269'\n",
      " '664' 'E887' '952' '164' 'E881' '527' '685' '366' '836' '27' 'V63' '865'\n",
      " '793' '232' '990' '52' '831' '327' '542' '806' '972' '862' 'E829' 'E919'\n",
      " '944' 'E916' '963' '316' '645' '347' 'V85' '374' 'V02' '748' '256' '186'\n",
      " '866' '975' '96' '395' '262' 'E819' '654' '994' '318' 'E826' '879' '674'\n",
      " '641' '822' '145' '797' '353' 'E938' 'E816' '948' '987' '99' '192'\n",
      " '250.3' 'E906' '534' '115' 'E818' 'E980' '360' '338' '529' '871' '750'\n",
      " '212' '302' '955' '141' '88' 'V25' '215' '350' 'V50' 'V03' 'E853' 'E968'\n",
      " 'E882' '140' '703' '991' '893' 'E821' '235' 'V69' '670' '195' 'V55' '388'\n",
      " '268' '894' '114' '260' '853' '7' '880' 'V86' '180' 'E945' '523' '863'\n",
      " '649' '270' '665' '460' '942' '364' '66' 'E883' '123' '884' 'V60' '843'\n",
      " '927']\n",
      "Nb de modalités : 749\n",
      "\n",
      "diag_3: ['?' '255' 'V27' '403' '250' 'V45' '38' '486' '996' '197' '250.6' '427'\n",
      " '627' '414' '416' '714' '428' '582' 'V43' '250.01' '263' '250.42' '276'\n",
      " '482' '401' '250.41' '585' '781' '278' '998' '568' '682' '618' '250.02'\n",
      " '305' '707' '496' '599' '715' '424' '518' '553' '794' '411' 'V42' '531'\n",
      " '511' '490' '562' '250.8' '250.7' '250.52' '784' '491' '581' '420' '8'\n",
      " '724' '730' '789' '131' '250.82' '999' '41' '493' '250.03' '753' '786'\n",
      " '529' 'E888' '425' '595' '303' '560' '711' '492' '332' '296' '438' '362'\n",
      " '250.4' '654' '244' 'V70' '737' '625' '681' '250.51' '404' 'V10' '810'\n",
      " '280' '440' '785' '588' '569' '272' '997' '250.43' '918' '584' '54' '788'\n",
      " '426' '722' '250.92' '196' '461' '535' '787' '891' '284' '458' '648'\n",
      " '780' '182' '285' '593' '413' '664' '564' '201' '356' 'V15' '292' '782'\n",
      " '473' '455' 'E932' '357' '348' '294' '250.23' '459' 'E878' '437' '733'\n",
      " '507' '525' '250.53' '397' '572' '805' '453' '331' '736' '402' '591'\n",
      " '576' '465' '533' '703' '349' '315' '658' '608' '578' '716' '382' '300'\n",
      " '282' '571' '536' '596' '287' '644' 'V11' '558' 'E885' '162' '198' '218'\n",
      " '412' '396' 'V14' '570' '433' 'E934' '882' '288' '577' '443' '729' '836'\n",
      " '295' '799' '281' '304' '153' '410' '616' '250.83' '601' '291' '75' '512'\n",
      " '660' '250.5' '598' '337' '574' '653' 'V58' '311' '415' '386' '602' '790'\n",
      " '112' '873' '620' '436' '70' '155' '138' '663' '530' '710' '42' '342'\n",
      " '250.91' 'E884' '515' '307' '704' '728' '731' '583' '238' '441' '293'\n",
      " '573' '532' '290' '594' '319' '250.13' '250.12' '519' '346' '380' '135'\n",
      " '642' '698' '924' '905' 'E933' '555' '309' 'E879' '286' '565' '752' '580'\n",
      " '446' '444' '344' '252' '35' '813' '394' '301' '575' '258' 'V17' '802'\n",
      " '435' '746' 'V12' '709' '881' 'E935' '139' '250.81' '718' '365' '202'\n",
      " '334' '185' '398' 'V44' '517' 'E849' '614' '466' '626' '250.9' '368'\n",
      " '605' '883' '289' '478' '617' '429' '442' 'V25' '866' '610' '557' '959'\n",
      " 'E942' '94' '920' '345' '313' '379' '79' '516' '586' '821' '600' '242'\n",
      " '373' '592' 'V64' '487' '253' '706' 'E947' '117' '340' 'E950' '656'\n",
      " 'E949' '590' 'V09' '250.22' '934' '694' '203' '250.93' '995' '726' '923'\n",
      " '958' '275' 'E929' '211' 'V18' 'V66' '199' '665' '53' '279' '522' '791'\n",
      " '890' '456' 'E938' 'E816' '122' '721' 'V65' '136' '480' '423' 'E920'\n",
      " '793' '647' '537' '351' '845' '336' '274' '719' '945' '434' '494' '227'\n",
      " '157' '208' '174' 'V57' '812' '734' '150' 'V23' '447' '692' '228' 'V16'\n",
      " '756' '405' 'E928' '823' '552' '528' '389' '240' '454' '792' '366' 'E939'\n",
      " '907' '270' '310' '266' '387' 'E931' '783' '245' '607' '355' 'E930' '705'\n",
      " '372' '369' '611' '283' 'V46' '110' '867' 'E956' '251' '250.2' '820'\n",
      " '712' '695' '567' '343' '723' 'V08' '273' '623' '807' '451' '495' '701'\n",
      " '34' 'V53' '314' '472' 'E945' '11' '189' '534' '354' '333' 'V54' '277'\n",
      " '659' '708' '452' '655' '816' '670' '621' '246' '953' '865' 'E817' '646'\n",
      " '151' '378' '78' '298' '840' '641' '521' '745' '619' '912' '506' 'E904'\n",
      " '259' 'E870' 'E980' '383' '204' '696' '566' '727' '47' 'E943' '358' '191'\n",
      " '965' '921' '432' '27' 'E861' '758' '477' '524' '751' '652' '556' '188'\n",
      " '825' '919' '732' '908' '951' '962' '685' 'E850' 'E944' '527' '341' '693'\n",
      " '250.1' 'V49' '860' '323' 'V55' '579' '508' '969' '205' '462' 'E880'\n",
      " '680' '697' '826' '200' '457' '717' '738' '742' '735' '235' '308' '725'\n",
      " '241' '824' '464' '260' '917' '239' '661' '892' '261' 'E883' '943' '744'\n",
      " 'E936' '796' '318' '967' '350' '854' 'E905' '9' '741' 'E941' '170' '643'\n",
      " '317' '759' '909' 'V22' '831' '713' '180' '801' '360' '359' '501' '335'\n",
      " '250.11' '306' '811' '690' 'V02' '271' '214' '847' '543' 'V63' '906'\n",
      " '842' '686' '445' '808' '861' 'E852' '220' 'E887' 'E858' '915' '970'\n",
      " '256' '747' '395' '243' '815' '481' '5' 'E927' '297' '299' '851' '864'\n",
      " '922' '384' 'E876' '225' '158' 'E937' '871' '88' '966' 'E917' 'E812'\n",
      " 'V62' 'E924' '604' '233' 'E916' '377' '797' 'V72' '172' '7' '421' '852'\n",
      " 'E819' '972' '916' '956' '3' 'E965' '173' '193' '154' '347' '862' '250.3'\n",
      " '987' '470' '262' 'E855' '161' '115' '179' '910' '312' '17' '460' '265'\n",
      " '66' '163' 'V60' '870' 'E906' '514' '944' '844' '417' '152' '183' '991'\n",
      " '216' '385' '164' '935' '510' '814' '485' '850' '250.21' 'E919' '872'\n",
      " '195' '431' '597' '933' '171' '884' '156' '868' '483' 'E815' '542' 'V61'\n",
      " '853' '374' 'E881' 'E882' 'E822' '192' '754' '327' '523' '500' 'V85'\n",
      " '992' '657' '684' '603' 'E826' '550' '913' '376' '755' '361' '186' '720'\n",
      " '250.31' '674' '911' 'E813' '226' '365.44' 'E818' '146' '955' 'E894'\n",
      " '475' 'V13' '880' '930' 'E915' '381' '132' '353' '795' '893' 'V01' 'E853'\n",
      " '863' '540' 'E828' '430' '800' 'E865' '148' 'E946' '822' '879' '848'\n",
      " 'V86' 'V03' '338' '989' '388' 'E966' '111' 'E922' '123' '757' 'E901'\n",
      " '141' '268' 'E892' '649' '702' '948' '223' '484' 'E886' '838' '928' '236'\n",
      " '624' '837' 'E987' 'V07' '841' '622' 'E912' 'E955' '463' 'V06' 'E864'\n",
      " '217' '877' '391' 'E825' '952' '669' '875' 'E900' '215' '538' '980' '834'\n",
      " '448' '175' '49' '876' '230' '57' 'E854' '942' '14' '750' '370' '671'\n",
      " '971']\n",
      "Nb de modalités : 790\n",
      "\n",
      "number_diagnoses: [ 1  9  6  7  5  8  3  4  2 16 12 13 15 10 11 14]\n",
      "Nb de modalités : 16\n",
      "\n",
      "max_glu_serum: ['None' '>300' 'Norm' '>200']\n",
      "Nb de modalités : 4\n",
      "\n",
      "A1Cresult: ['None' '>7' '>8' 'Norm']\n",
      "Nb de modalités : 4\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metformin: ['No' 'Steady' 'Up' 'Down']\n",
      "Nb de modalités : 4\n",
      "\n",
      "repaglinide: ['No' 'Up' 'Steady' 'Down']\n",
      "Nb de modalités : 4\n",
      "\n",
      "nateglinide: ['No' 'Steady' 'Down' 'Up']\n",
      "Nb de modalités : 4\n",
      "\n",
      "chlorpropamide: ['No' 'Steady' 'Down' 'Up']\n",
      "Nb de modalités : 4\n",
      "\n",
      "glimepiride: ['No' 'Steady' 'Down' 'Up']\n",
      "Nb de modalités : 4\n",
      "\n",
      "acetohexamide: ['No' 'Steady']\n",
      "Nb de modalités : 2\n",
      "\n",
      "glipizide: ['No' 'Steady' 'Up' 'Down']\n",
      "Nb de modalités : 4\n",
      "\n",
      "glyburide: ['No' 'Steady' 'Up' 'Down']\n",
      "Nb de modalités : 4\n",
      "\n",
      "tolbutamide: ['No' 'Steady']\n",
      "Nb de modalités : 2\n",
      "\n",
      "pioglitazone: ['No' 'Steady' 'Up' 'Down']\n",
      "Nb de modalités : 4\n",
      "\n",
      "rosiglitazone: ['No' 'Steady' 'Up' 'Down']\n",
      "Nb de modalités : 4\n",
      "\n",
      "acarbose: ['No' 'Steady' 'Up' 'Down']\n",
      "Nb de modalités : 4\n",
      "\n",
      "miglitol: ['No' 'Steady' 'Down' 'Up']\n",
      "Nb de modalités : 4\n",
      "\n",
      "troglitazone: ['No' 'Steady']\n",
      "Nb de modalités : 2\n",
      "\n",
      "tolazamide: ['No' 'Steady' 'Up']\n",
      "Nb de modalités : 3\n",
      "\n",
      "examide: ['No']\n",
      "Nb de modalités : 1\n",
      "\n",
      "citoglipton: ['No']\n",
      "Nb de modalités : 1\n",
      "\n",
      "insulin: ['No' 'Up' 'Steady' 'Down']\n",
      "Nb de modalités : 4\n",
      "\n",
      "glyburide-metformin: ['No' 'Steady' 'Down' 'Up']\n",
      "Nb de modalités : 4\n",
      "\n",
      "glipizide-metformin: ['No' 'Steady']\n",
      "Nb de modalités : 2\n",
      "\n",
      "glimepiride-pioglitazone: ['No' 'Steady']\n",
      "Nb de modalités : 2\n",
      "\n",
      "metformin-rosiglitazone: ['No' 'Steady']\n",
      "Nb de modalités : 2\n",
      "\n",
      "metformin-pioglitazone: ['No' 'Steady']\n",
      "Nb de modalités : 2\n",
      "\n",
      "change: ['No' 'Ch']\n",
      "Nb de modalités : 2\n",
      "\n",
      "diabetesMed: ['No' 'Yes']\n",
      "Nb de modalités : 2\n",
      "\n",
      "readmitted: ['NO' '>30' '<30']\n",
      "Nb de modalités : 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Indique la nature et le nombre de modalités pour chacune des colonnes\n",
    "\n",
    "####################\n",
    "# A FAIRE : ajouter un paramètre dans la fonction permettant de sélectionner les colonnes dont on veut avoir le détail\n",
    "# -> def modalites(df, columns=[]):\n",
    "####################\n",
    "\n",
    "def modalites(df):\n",
    "    for i in df.columns:\n",
    "        print(f'{i}: {df[i].unique()}')\n",
    "        print(f'Nb de modalités : {df[i].value_counts().count()}\\n')\n",
    "\n",
    "modalites(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a59625",
   "metadata": {},
   "source": [
    "## La target : réadmission ou non du patient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1834cf56",
   "metadata": {},
   "source": [
    "Notre target est la variable 'readmitted' : il s'agira de prédire si, au regard des caractéristiques ci-dessus, le patient sera réadmis ou non ultérieurement dans le service diabétologie.\n",
    "\n",
    "Nous avons là deux possibilités :  \n",
    "    - effectuer une classification mutliclasse (dans ce cas, vérifier le déséquilibre des classes et le corriger avec la méthode Smote par exemple)   \n",
    "    - rassembler la target en une variable binaire (0 = pas de réadmission / 1 = réadmission (>30 et <30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2990b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f6ad1d",
   "metadata": {},
   "source": [
    "# Traitement nécessaire avant exploration des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b8327c",
   "metadata": {},
   "source": [
    "## Analyse des caractères anormaux du dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baa87ef",
   "metadata": {},
   "source": [
    "Nous observons des \"?\" : nous les remplaçons par des Nan.\n",
    "Nous observons de nombreux \"None\" : pour l'instant, nous ne les changeons pas en null (donc pas de drop) car elles font partie de modalités de deux features importantes (max_glu_serum et A1Cresult). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2b177b",
   "metadata": {},
   "source": [
    "**Questions** : \n",
    "- faut-il supprimer les \"-\" de la variable \"medical_specialty\" ? \n",
    "- faut-il bien considérer les None comme des valeurs nulles ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6425b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# A FAIRE : refactoriser le code en mettant les 3 étapes dans une fonction def\n",
    "##########\n",
    "\n",
    "# Quelles sont les colonnes qui contiennent des \"?\"\n",
    "\n",
    "def columns_with_interrogation(df): \n",
    "    list = []\n",
    "    [list.append(i) for i in df.columns if np.any(df[i] == '?')] # list comprehension  \n",
    "    return list\n",
    "\n",
    "# Combien de lignes par colonnes sont concernées ? \n",
    "\n",
    "interrogation = columns_with_interrogation(data)\n",
    "\n",
    "for i in interrogation:\n",
    "    number = data[i] == '?'\n",
    "    total = number.sum()\n",
    "    print(f'La colonne \"{i}\" en contient : {total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd98728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacement des ? par des nan\n",
    "\n",
    "data = data.replace({'?' : np.nan})\n",
    "columns_with_interrogation(data) # on vérifie qu'on n'a plus de colonnes impactées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53619226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de la présence des None\n",
    "\n",
    "def columns_with_None(data):\n",
    "    list = []\n",
    "    [list.append(i) for i in data.columns if np.any(data[i] == 'None')] # list comprehension  \n",
    "    return list\n",
    "\n",
    "None_columns = columns_with_None(data)\n",
    "\n",
    "for i in None_columns:\n",
    "    number = data[i] == 'None'\n",
    "    total = number.sum()\n",
    "    print(f'La colonne \"{i}\" en contient : {total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979fa269",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# les \"?\" ont bien été remplacés par des Nan\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ee4d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La modalité \"Unknown/Invalid\" de colonne 'gender' contient un caratère spécial, et est de toute façon à considérer \n",
    "# comme un Null, donc nous la qualifions en nan.  \n",
    "\n",
    "data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb3013",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace({'Unknown/Invalid' : np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c5f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1193ef7e",
   "metadata": {},
   "source": [
    "## Suppression de l'Id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec3f2c8",
   "metadata": {},
   "source": [
    "Variable integer inutile qui va parasiter notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6805284b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(columns=['encounter_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796ed351",
   "metadata": {},
   "source": [
    "## Vérification des doublons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4859e9e3",
   "metadata": {},
   "source": [
    "On ne constate aucun doublon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693fed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated(keep=False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32dbd93",
   "metadata": {},
   "source": [
    "## Encodage de la target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8519fc4e",
   "metadata": {},
   "source": [
    "Notre intérêt ici est de savoir si le patient, suite à son séjour hospitalier, risque d'être de nouveau hospitalisé. Nous ne prenons pas en compte la granularité de temps (à moins ou plus de 30 jours). Nous optons donc pour une variable binaire et non multiclasse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136ef54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace({'readmitted' : {'NO' : 0, '>30' : 1, '<30' : 1}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e7b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb d'exemples pour chaque modalité de la colonne readmitted\n",
    "\n",
    "data.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157cd684",
   "metadata": {},
   "source": [
    "# Itération 1 : baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be99453e",
   "metadata": {},
   "source": [
    "**Objectif** : créer un modèle prédictif simple, basé sur une analyse exploratoire et une data préparation sommaires afin de comprendre un peu mieux la structure du dataset et de pouvoir élaborer une ébauche de l'application demandée. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0932ec",
   "metadata": {},
   "source": [
    "## Analyse de forme des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42fa4b1",
   "metadata": {},
   "source": [
    "**- Target** : readmitted - la classe est équilibrée (0 : 53% / 1 : 46%)  \n",
    "**- Lignes et colonnes** : 101766 lignes et  49 colonnes  \n",
    "**- Types de variables** : int64 = 13, object = 36 dont 5 avec plus de 10 modalités  \n",
    "**- Valeurs manquantes**: 7 colonnes ont des valeurs manquantes dont 'weight' à hauteur de 96%. 'medical_specialty' et 'payer_code' manquent respectivement à 50% et 40%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb04db2",
   "metadata": {},
   "source": [
    "### Structure du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1221d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On travaille sur une copie du dataset initial\n",
    "\n",
    "baseline = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcc3345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La target 'readmitted'\n",
    "\n",
    "def analyse_target(data) : \n",
    "    number = data.readmitted.value_counts()\n",
    "    percentage = data.readmitted.value_counts(normalize=True).round(3)*100\n",
    "    analyse_target = {'number': number, '%': percentage}\n",
    "    analyse_target_1 = pd.DataFrame(analyse_target)\n",
    "    return analyse_target_1\n",
    "    \n",
    "analyse_target(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c4bb69",
   "metadata": {},
   "source": [
    "**Question** : Quel est le degré de documentation du code qui est demandé ? Exemple documentation de la fonction ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d24cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de Lignes et colonnes\n",
    "\n",
    "baseline.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be3986d",
   "metadata": {},
   "source": [
    "### Types de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fec63b",
   "metadata": {},
   "source": [
    "A ce stade, nous avons 36 variables qualitatives dont 5 contiennent plus de 10 modalités, et 13 quantitatives.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d057b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048807bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Répartition du type de variables\n",
    "\n",
    "##################\n",
    "# A faire : intégrer les valeurs dans le pie et retirer le None\n",
    "#################\n",
    "\n",
    "baseline.dtypes.value_counts().plot.pie()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d4443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_dtypes_object(data):\n",
    "    return data.select_dtypes(include=('object')).nunique().sort_values(ascending=False)\n",
    "\n",
    "analyse_dtypes_object(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f070dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiche le plot des modalités pour toutes les variables catégorielles\n",
    "\n",
    "#############\n",
    "# A FAIRE : reprendre le graph avec d'autres bins pour plus de précision sur l'intervalle [0 - 100]\n",
    "############\n",
    "\n",
    "baseline.select_dtypes(include=('object')).nunique().hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cc777c",
   "metadata": {},
   "source": [
    "### Valeurs nulles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a56f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_missing_values(data):\n",
    "    plt.figure(figsize=(17,7))\n",
    "    heatmap = sns.heatmap(data.isna(), cbar=False, cmap=\"Blues\")\n",
    "    heatmap.set_title('Heatmap des valeurs manquantes du dataset',\n",
    "    fontdict={'fontsize':18}, pad=16);\n",
    "    \n",
    "map_missing_values(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e83b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On affiche les valeurs nulles en ordre desc des 10 premières colonnes\n",
    "\n",
    "def check_null_values(df):\n",
    "    nb_null = df.isnull().sum().sort_values(ascending=False).head(10)\n",
    "    percentage_null = df.isnull().sum()*100/len(df)\n",
    "    percentage_null = percentage_null.sort_values(ascending=False).head(10).round(1)\n",
    "    null = {'nombre_null' : nb_null,'%_null' : percentage_null}\n",
    "    data = pd.DataFrame(data = null)\n",
    "    return data\n",
    "\n",
    "check_null_values(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47493085",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8644b4c2",
   "metadata": {},
   "source": [
    "### Suppression des valeurs nulles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f7b7f3",
   "metadata": {},
   "source": [
    "Pour notre modèle experimental (baseline), nous décidons de supprimer les colonnes qui ont plus de 40% de valeurs nulles(weight, medical_specialty, payer_code) et toutes les lignes possédant au moins une valeur nulle. \n",
    "Notre dataset se compose désormais de 98 052 exemples et 46 colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ceb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des colonnes ayant plus de 39% de valeurs nulles (isna)\n",
    "# Suppression des lignes ayant au moins une valeur nulle(dropna)\n",
    "\n",
    "##############\n",
    "# VOIR si refacto en personnalisant le pourcentage de façon optionnelle\n",
    "# def delete_columns_null_more_40_percent(data):\n",
    "#     data = data[data.columns[data.isna().sum()/data.shape[0] <0.4]]\n",
    "#     return data\n",
    "#############\n",
    "\n",
    "baseline = baseline[baseline.columns[baseline.isna().sum()/baseline.shape[0] <0.3]]\n",
    "baseline = baseline.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b289acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_null_values(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f6f97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e02ae74",
   "metadata": {},
   "source": [
    "### Sélection des variables et split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811f2191",
   "metadata": {},
   "source": [
    "On exclut :  \n",
    "- les variables qui n'ont qu'une modalité (examide/citoglipton) car elles n'apportent rien au modèle\n",
    "- les variables à plus de 10 modalités (diag_1/2/3) car elles vont créer de multiples dimensions lors de l'encodage, ce qui peut être lourd et et embrouiller l'algorithme. \n",
    "- la variable \"patient_nbr\" qui est un ID\n",
    "\n",
    "Notre dataset contient désormais : 98053 exemples et 39 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59468ad3",
   "metadata": {},
   "source": [
    "**Questions** : \n",
    "- 3 variables qualitatives correspondent à des modalités mais sont déjà encodées de façon ordinale : que faire ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2377a93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = baseline.drop(columns=['diag_3', 'diag_2', 'diag_1', 'citoglipton', 'examide', 'metformin-rosiglitazone', 'patient_nbr'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25090ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83637328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du X et du y\n",
    "\n",
    "# X = baseline.drop(columns=['readmitted'], axis=1)\n",
    "X = baseline[['time_in_hospital','num_lab_procedures','num_procedures','num_medications',\n",
    "              'number_outpatient','number_emergency', 'number_inpatient', 'number_diagnoses','age']]\n",
    "y = baseline[['readmitted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a7f8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de99ba2",
   "metadata": {},
   "source": [
    "=> N'ai pris que les variables catégorielles car cela faisait planter mes algo et les résultats étaient identiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b966f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split du dataset entre un jeu de données de train et de test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=5, stratify=y)\n",
    "\n",
    "print('Train set :', X_train.shape)\n",
    "print('Test set :', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4fb587",
   "metadata": {},
   "source": [
    "### Encodage et normalisation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ddaf3d9",
   "metadata": {},
   "source": [
    "Voir à quelle étape il est plus judicieux de faire le preprocessing (encodage + imputer) afin d'éviter au max le dataleakage. Voir Geron. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e75f6a",
   "metadata": {},
   "source": [
    "#### Transformation de la variable \"age\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1e87ed",
   "metadata": {},
   "source": [
    "La colonne \"age\" est classé selon un intervalle avec 10 modalités (object). \n",
    "Point d'attention : cette donnée perd en qualité car on ne sait pas comment la donnée initiale a été transformée.  \n",
    "Creuser pour savoir comment traiter cette variable plus efficacement. En attendant, nous allons la transformer en variable numérique en prenant la moyenne des extrêmes de l'intervalle. On aurait pu aussi envisager de faire un Ordinal encorder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74478ad7",
   "metadata": {},
   "source": [
    "**Question** : voir comment gérer cette question des intervalles -> si je les garde en l'état, mon algorithme va les considérer comme des variables catégorielles => Beaucoup trop lourd pour le modèle ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9173b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = baseline.replace({'age' : \n",
    "                            {'[0-10)' : 5, \n",
    "                             '[10-20)' : 15, \n",
    "                             '[20-30)' : 25, \n",
    "                             '[30-40)' : 35, \n",
    "                             '[40-50)' : 45,\n",
    "                             '[50-60)' : 55,\n",
    "                             '[60-70)' : 65,\n",
    "                             '[70-80)' : 75,\n",
    "                             '[80-90)' : 80, \n",
    "                             '[90-100)' : 95}\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f43dbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941a9dba",
   "metadata": {},
   "source": [
    "#### Pipeline de preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018fac5b",
   "metadata": {},
   "source": [
    "On crée un pipeline de pré-processing de façon à pouvoir transformer nos données plus facilement, à éviter d'avoir de la fuite de données (dataleakage) ou des données mal transformées. \n",
    "\n",
    "Nous avons des variables catégorielles pour lesquelles il serait plus pertinent de faire un OrdinalEncoder (mettre un poids en fonction du degré d'importance) mais pour notre baseline, nous allons plutôt utiliser le OneHotEncoder. Ce dernier représente chaque classe de façon binaire et les sépare en plusieurs dimensions. On évite ainsi les problème d'affection de poids sur la variable encodée. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a8eaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distinction entre les variables numériques et catégorielles\n",
    "\n",
    "numerical_features = X.select_dtypes(include=['float', 'integer']).columns.values\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62c8dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle_unknown = 'ignore' : pallier au fait que nous n'avons pas dans le X_test le même nombre de classes/modalités\n",
    "\n",
    "numerical_pipeline = make_pipeline(StandardScaler())\n",
    "categorical_pipeline = make_pipeline(OneHotEncoder(sparse = False,  handle_unknown = 'ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64473d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_column_transformer : permet d'appliquer les transformers sur les colonnes qu'on sélectionne\n",
    "\n",
    "preprocessor = make_column_transformer((numerical_pipeline, numerical_features),\n",
    "                                   (categorical_pipeline, categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e2b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a72ecd",
   "metadata": {},
   "source": [
    "## Entrainement du modèle et score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8787688f",
   "metadata": {},
   "source": [
    "### Choix du modèle et de la métrique de performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eff89f",
   "metadata": {},
   "source": [
    "#### La régression logistique"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2a97307",
   "metadata": {},
   "source": [
    "FAIRE LA REGRESSION LOGISTIQUE EN R&D + VOIR AVEC JULIE\n",
    "\n",
    "https://www.youtube.com/watch?v=0t2YlJqYsWU\n",
    "https://medium.com/tell-ia/la-r%C3%A9gression-logistique-expliqu%C3%A9e-%C3%A0-ma-grand-m%C3%A8re-52a2ab30788\n",
    "Notebook du MOOC de l'Inria : 07_logistic_regression / Permet de tracer la frontière de décision "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7ff091",
   "metadata": {},
   "source": [
    "#### Les métriques de performance choisies : fonctions coût"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bc9cee",
   "metadata": {},
   "source": [
    "Dans le cas où on considère notre application comme un outil d'aide à la décision médicale, nous voulons éviter les faux négatifs : on ne veut pas prédire qu'une personne ne retournera pas l'hôpital alors qu'elle aurait dû. Pour des raisons de santé, il est préférable qu'on dise qu'elle vienne, même si c'est une fausse alerte, plutôt que de penser qu'elle ne fera pas de nouveau une crise de diabète. Nous allons donc nous attacher à obtenir un bon RECALL.  \n",
    "En revanche, nous ne voulons pas non plus que les hôpitaux soient \"engorgés\" et il nous faut limiter les faux positifs. Nous veillerons donc également à obtenir une PRECISION convenable.  \n",
    "Dans la mesure où nous avons besoin d'un rapport entre la precision et le recall honorable, nous avons tout intérêt à veiller à ce que notre F1 SCORE soit optimisé (il calcule le rapport moyen entre les 2 métriques grâce à une moyenne harmonique). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cdf3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voir ontenote Régression logistique binaire\n",
    "\n",
    "# Régression logistique = paramétrique => suit la règle des présupposés\n",
    "\n",
    "# Reprendre les 4 étapes de ML : dataset, métrique de performance, fonction coût, algo de minimisation du coût"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc5831f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8c108a2",
   "metadata": {},
   "source": [
    "### Entraînement & score en cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eecc3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expliquer la cross validation et ses avantages\n",
    "# - évite le data leakage notamment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b655bcf",
   "metadata": {},
   "source": [
    "#### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efb9aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix du model\n",
    "model = make_pipeline(preprocessor, LogisticRegression(random_state = 5, solver='lbfgs')) # solver='lbfgs' mis suite à message d'erreur\n",
    "\n",
    "# Entrainement\n",
    "model.fit(X_train, y_train.values.ravel()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9df9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score en cross_validation\n",
    "score_cv = cross_val_score(model, X_train, y_train.values.ravel(), cv=5, scoring='accuracy').mean()\n",
    "score_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283d1316",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# Vérifier que ce soit bon\n",
    "#############################\n",
    "\n",
    "cv_y_pred = model.predict(X_train)\n",
    "cv_y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53bafa8",
   "metadata": {},
   "source": [
    "#### Matrice de confusion en cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb1bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "confusion_matrix(y_train, cv_y_pred)\n",
    "\n",
    "conf_cv = pd.DataFrame(confusion_matrix(y_train, cv_y_pred))\n",
    "conf_cv = conf_cv.rename(columns={0: 'Predicted 0',1:'Predicted 1'})\n",
    "conf_cv= conf_cv.rename(index={0: 'Actual 0',1:\"Actual 1\"})\n",
    "# conf_cv[\"TOTAL\"] = conf_cv[\"Predicted 0\"]+conf_cv[\"Predicted 1\"]\n",
    "# conf_cv = conf_cv.append(pd.Series(conf_cv.sum(axis=0), name=\"TOTAL\"))\n",
    "conf_cv "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db13ac59",
   "metadata": {},
   "source": [
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2cd415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_train, cv_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d009d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Faire une phrase simple d'interprétation avec toutes les métriques de performance\n",
    "####################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931eca0c",
   "metadata": {},
   "source": [
    "On doit éviter les faux négatifs (prédire que la personne n'est pas réadmise alors qu'elle revient) => recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fc2945",
   "metadata": {},
   "source": [
    "#### La courbe AUC/ROC"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b42ffd41",
   "metadata": {},
   "source": [
    "# Courbe ROC\n",
    "\n",
    "# (repris de la préparation de la certification Microsoft AI900)\n",
    "# Tracé qui met en corrélation le taux de faux positif et le taux de vrais positifs.\n",
    "# Représente la performance attendue pour une estimation totalement aléatoire pour chaque patient, ce qui reviendrait à tirer à pile ou face : vous pourriez vous attendre à un résultat correct dans la moitié des cas (et à un résultat incorrect dans la moitié des cas) environ. La zone sous la ligne diagonale représente donc un AUC de 0.5. Si l’AUC de votre modèle est supérieure pour un modèle de classification binaire, alors il est plus performant qu’une estimation aléatoire.\n",
    "# + ROC / AUC -> doit être au dessus de 0.5. Mieux d'être le plus proche de 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8206df",
   "metadata": {},
   "source": [
    "#### Mesurer l'overfitting grâce à la learning curve cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f8eaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# A FAIRE : \n",
    "# - faire une fonction pour la learning_curve_cv et learning_curve_dataset\n",
    "# - vérifier que les X et y doivent bien être renseignés par le X_train et le y_train\n",
    "# - Afin d'analyser plus finement nos trois métriques, faire un tableau matplotlib avec une learning curve pour chacune\n",
    "#########################\n",
    "\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# learning curve returns : train_size, train_score, test_score\n",
    "\n",
    "train_sizes, train_scores, validation_scores = learning_curve(estimator = model, \n",
    "                                                              X = X_train,\n",
    "                                                              y = y_train.values.ravel(),\n",
    "                                                              train_sizes = ([10000,20000,30000,40000,50000, 60000]),\n",
    "                                                              cv = 5,\n",
    "                                                              scoring = 'precision')\n",
    "\n",
    "plt.plot(train_sizes,np.mean(train_scores,axis=1), label= 'training set')\n",
    "plt.plot(train_sizes,np.mean(validation_scores,axis=1), label= 'validation set')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127263fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avec la precision : bonne convergence entre les 2 courbes -> montre une tendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.datasets import load_game\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "\n",
    "train_sizes = ([10000,20000,30000,40000,50000, 60000])\n",
    "\n",
    "visualizer = LearningCurve(\n",
    "    model, cv=5, scoring='precision', train_sizes=train_sizes, n_jobs=4\n",
    ")\n",
    "\n",
    "visualizer.fit(X_train, y_train) # Fit the data to the visualizer\n",
    "visualizer.show() # Finalize and render the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1ea3a26",
   "metadata": {},
   "source": [
    "# Analyse avec Flo : \n",
    "- la learning curve de la cross validation avec la métrique \"précision\" montre une belle tendance (avec une faible variance) : notre modèle n'a pas surappris avec les données d'entrainement et est capable de généraliser.\n",
    "- L'objectif de la learning curve est de comprendre la structure de la donnée et d'avoir un train qui baisse (elle ne surapprend pas) et un test qui augmente (ce qui montre une bonne généralisation). \n",
    "\n",
    "# Note perso/mon analyse : \n",
    "- On pourrait se dire que c'est bon le ratio mais on constate qe \n",
    "- Ne sommes-nous pas à la limite de l'underfitting car les erreurs peuvent être considérées comme grandes sur le train et sur le test => biais assez important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975acf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Vérifier que cette étape est bien à indiquer ici\n",
    "#########################\n",
    "\n",
    "Lorsque les résultats sont probants avec la cross validation, on peut scorer sur notre jeu de test (y_test). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b995bd",
   "metadata": {},
   "source": [
    "### Score sur le test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b803f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score sur mon jeu de test\n",
    "\n",
    "score = model.score(X_test,y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b8c1da",
   "metadata": {},
   "source": [
    "**Interprétation**  \n",
    "A priori, notre modèle ne semble pas overfitter : le score en cross validation et sur le jeu de test final ne montrent pas de surapprentissage et le modèle semble bien généraliser car nous avons à peu près les mêmes scores. \n",
    "L'accuracy  mériterait toutefois d'être améliorée, notamment grâce à l'optimisation des hyperparamètres et avec un preprocessing plus élaboré. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc9c98f",
   "metadata": {},
   "source": [
    "#### Learning curve sur le test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b34042",
   "metadata": {},
   "source": [
    "#### Métriques de performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71e50dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reprendre celles vues précédemment => faire des fonctions pour récupérer les bons paramètres avec un paramètres \n",
    "# optionnel pour la cross_validation ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca1e143",
   "metadata": {},
   "source": [
    "Mon modèle généralise bien, je peux donc l'entraîner sur l'ensemble de mon dataset et enregistrer mon predict. Avec une accuracy de 0.6, je peux avoir confiance en mon modèle à 60% (vérifier cette interprétation qui me semble peu précise). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ba5ce5",
   "metadata": {},
   "source": [
    "### Score sur l'ensemble du data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f050d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X, y)\n",
    "\n",
    "model.fit(X,y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a0a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eed770c",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c37f9f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Renvoie la prediction du label en fonction de X\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X)[\u001b[38;5;241m25\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Renvoie la prediction du label en fonction de X\n",
    "\n",
    "model.predict(X)[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a67329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renvoie une probabilité pour chaque label\n",
    "# Interprétation : L'item 25 a 56% d'appartenir à la classe 0 et 43% d'appartenir à la classe 1.\n",
    "\n",
    "model.predict_proba(X)[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca6079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple predict avec une variable = tester\n",
    "\n",
    "'''\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(data[[\"OverallQual\"]], data[\"Log_SalePrice\"])\n",
    "print(f'R2 ==> {reg.score(data[[\"OverallQual\"]], data[\"Log_SalePrice\"])}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608b1470",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Essayons de prédire le prix d'une maison affichant une qualité de 6:\n",
    "def price_predict():\n",
    "    quality = float(input(\"Indiquez la qualité de votre bien - Nombre de 0 à 10 ==> \"))    \n",
    "    result = reg.predict([[quality]])\n",
    "    result = np.exp(result)\n",
    "    print(f\"Le prix que vous pouvez obtenir pour votre maison est estimé à environ {result} dollars\")\n",
    "price_predict()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d53961",
   "metadata": {},
   "source": [
    "### Sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6716da3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4a4ee09",
   "metadata": {},
   "source": [
    "## Les présupposés de la régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa620a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf5e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a625656",
   "metadata": {},
   "source": [
    "Aborder cette étape comme une façon plus précise de voir comment notre modèle se comporte et voir des pistes d'amléioration du modèle => confirmer aussi avec Jonathan. \n",
    "\n",
    "Voir Note\n",
    "\n",
    "Vu avec Flo : \n",
    "Les présupposés sont : \n",
    "- échantillon représentatif\n",
    "- absence de multicolinéarité (attention, correlation ne veut pas dire multicolinéarité)\n",
    "    => Faire le VIF (si on soupçonne colinéarité) // revoir plus précisément ce point\n",
    "- normalité des résidus\n",
    "- homoscédasticité des erreurs (variance)\n",
    "\n",
    "Autre alternative à la vérification des présupposés : utiliser le modèle Random Forest qui est un modèle non-paramétrique => sans présupposés. Si on obtient le même score avec le Random Forest, on peut supposer que les présupposés de la régression logistique sont réunis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba23e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test d'entrainement avec une feature pour input 1 feature dans l'Api (pour la compréhension de la méthode)\n",
    "# Avec le X_train\n",
    "# 'time_in_hospital'\n",
    "\n",
    "fit_1_feature = model.fit(baseline['number_diagnoses'], baseline['readmitted'])\n",
    "# fit_1_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e4be5",
   "metadata": {},
   "source": [
    "## Analyse avec statmodel ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b476009d",
   "metadata": {},
   "source": [
    "## Analyse de cette première itération & actions à mener"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4c56adc",
   "metadata": {},
   "source": [
    "/!\\ Bien faire le Jira avant d'attaquer la seconde itération\n",
    "\n",
    "Suggestions de Florian : \n",
    "- Faire le VIF (pour supprimes les variables multicolinéaires\n",
    "- PCA pour réduire les dimensios et décolinéariser les features => augmente la confiance du score \n",
    "\n",
    "- Proposer des pistes d'amélioration suite au bouclage de l'itération 1 (+ revoir la logique du notebook sur les éoliennes)\n",
    "- Optimiser les paramètres avec le GridSearch CV / RandomizedSearch (voir le tuto de Machine Learnia qui utilise la validation curve, notamment pour savoir quels sont les meilleurs paramètres à prendre en compte)\n",
    "- Faire du feature enginering\n",
    "- Data viz pour valider la compétence de visualisation des données -> retenir le conseil de Jonathan (la visualisation des données sert plus à savoir s'il faut modifier la donnée (logarithme, etc.) en analysant la forme de la courbe plutôt que de savoir quelles features conserver).\n",
    "\n",
    "- Envisager le SGD Classifier qui utilise la Descente de gradient (contrairement à la logistique classique) ??? = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4182f5",
   "metadata": {},
   "source": [
    "# Idées en vrac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52226ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voir si nécessité d'ajouter en intro une partie sur la compréhension de la problématique (voir livre de Geron\n",
    "# et Machine Learnia) \n",
    "\n",
    "# Pour le nettoyage des données : \n",
    "    # Voir comment gérer la colonne 'race' : pour le même id = pas la même race attribuée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a196ce9d",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f8fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre d'admissions par patient\n",
    "# Filtrer pour n'ajouter que ceux qui ont une admission supérieure à 1 \n",
    "# Connaitre le nombre de patient par nombre d'admission (groupeby n?)\n",
    "# df.patient_nbr.value_counts()\n",
    "\n",
    "# Très peu de données sur le poids mais peut-être intéressant d'indiquer cette variable => voir si\n",
    "# suffisamment probant en termes de représentabilité de classe d'age pour le remplacer ?? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f4c256",
   "metadata": {},
   "source": [
    "## Variables qualitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239eb288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour la correlation entre mes variables qualitatives et ma target, utiliser la fonction crosstab (vu avec Machine\n",
    "# Learnia) + tenter le Khi-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8ab6f6",
   "metadata": {},
   "source": [
    "## Outils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ae6f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas profiling \n",
    "# retrouver bibliothèque qui permet de faire viz rapidement (check) pour l'EDA de la baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88c2a22",
   "metadata": {},
   "source": [
    "# Catalogue des fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datavisualisation\n",
    "\n",
    "def analyse_dtypes_object(data):\n",
    "    return data.select_dtypes(include=('object')).nunique().sort_values(ascending=False)\n",
    "\n",
    "def analyse_target(data) : \n",
    "    number = data.readmitted.value_counts()\n",
    "    percentage = data.readmitted.value_counts(normalize=True).round(3)*100\n",
    "    analyse_target = {'number': number, '%': percentage}\n",
    "    analyse_target_1 = pd.DataFrame(analyse_target)\n",
    "    return analyse_target_1\n",
    "\n",
    "def map_missing_values(data):\n",
    "    plt.figure(figsize=(17,7))\n",
    "    heatmap = sns.heatmap(data.isna(), cbar=False, cmap=\"Blues\")\n",
    "    heatmap.set_title('Heatmap des valeurs manquantes du dataset',\n",
    "    fontdict={'fontsize':18}, pad=16);\n",
    "\n",
    "def check_null_values(df):\n",
    "    nb_null = df.isnull().sum().sort_values(ascending=False).head(10)\n",
    "    percentage_null = df.isnull().sum()*100/len(df)\n",
    "    percentage_null = percentage_null.sort_values(ascending=False).head(10).round(1)\n",
    "    null = {'nombre_null' : nb_null,'%_null' : percentage_null}\n",
    "    data = pd.DataFrame(data = null)\n",
    "    return data\n",
    "    \n",
    "# Preprocessing\n",
    "\n",
    "def columns_with_interrogation(df):\n",
    "    list = []\n",
    "    [list.append(i) for i in df.columns if np.any(df[i] == '?')]\n",
    "\n",
    "def modalites(df):\n",
    "    for i in df.columns:\n",
    "        print(f'{i}: {df[i].unique()}')\n",
    "        print(f'Nb de modalités : {df[i].value_counts().count()}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "364.705px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
